{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Natural Language Processing Lab\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab, we'll explore scikit-learn and NLTK's capabilities for processing text even further. We'll use the 20 newsgroups data set, which is provided by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chonn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard data science imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the scikit-learn data set:\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use the `fetch_20newsgroups` function to download a training and testing set.\n",
    "\n",
    "The \"20 Newsgroups\" dataset is described [here](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html).\n",
    "\n",
    "For this lab let's choose 4 categories to analyze.  The full list is given below.\n",
    "\n",
    "\n",
    "```python\n",
    "['alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']\n",
    "```\n",
    "\n",
    "Note that the solution code will use these categories:\n",
    "- `alt.atheism`\n",
    "- `talk.religion.misc`\n",
    "- `comp.graphics`\n",
    "- `sci.space`\n",
    "\n",
    "Also remove the headers, footers, and quotes using the `remove` keyword argument of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Information from the Data's Dictionary format\n",
    "\n",
    "categories = ['comp.sys.mac.hardware','comp.windows.x','misc.forsale','rec.autos']  # Fill in whatever categories you want to use!!\n",
    "\n",
    "# Setting out training data\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "# Setting our testing data\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What does the `shuffle` argument do?  Why are we setting a `random_state`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: The shuffle argument in fetch_20newsgroups() controls whether the training data is shuffled before being returned\n",
    "# A: The random_state argument controls the random seed used to shuffle the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Inspect the data.\n",
    "\n",
    "We've downloaded a few `newsgroups` categories and removed their headers, footers, and quotes.\n",
    "\n",
    "Because this is a scikit-learn data set, it comes with pre-split training and testing sets (note: we were able to call \"train\" and \"test\" in subset).\n",
    "\n",
    "Let's inspect them.\n",
    "\n",
    "1) What data type is `data_train`?\n",
    "- Is it a list? A dictionary? What else?\n",
    "- How many data points does it contain?\n",
    "- Inspect the first data point. What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A:\n",
    "type(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 2350\n"
     ]
    }
   ],
   "source": [
    "# Number of data points\n",
    "num_data_points = len(data_train.data)\n",
    "print(f\"Number of data points: {num_data_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First data point:\n",
      "Dumbest options? Well here in the UK, BMW offer a 'no-smokers' option...\n",
      "It just means they take the fag lighter out.... big deal....\n",
      "\n",
      "BTW - I just bought a Honda CRX F1..... its neat... did consider an MR2 targa,\n",
      "MX5 (you guys call it Miata?).... but that CRX just one my heart with that \n",
      "body kit and 8-spokes.... \n"
     ]
    }
   ],
   "source": [
    "# Inspect the first data point\n",
    "first_data_point = data_train.data[0]\n",
    "print(\"First data point:\")\n",
    "print(first_data_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create a bag-of-words model.\n",
    "\n",
    "Let's train a model using a simple count vectorizer.\n",
    "\n",
    "1) Initialize a standard CountVectorizer and fit the training data.\n",
    "- How big is the feature dictionary?\n",
    "- Eliminate English stop words.\n",
    "- Is the dictionary smaller?\n",
    "- Transform the training data using the trained vectorizer.\n",
    "- Evaluate the performance of a logistic regression on the features extracted by the CountVectorizer.\n",
    "    - You will have to transform the `test_set`, too. Be careful to use the trained vectorizer without refitting it.\n",
    "\n",
    "**Bonus**\n",
    "- Try a couple of modifications:\n",
    "    - Restrict the `max_features`.\n",
    "    - Change the `max_df` and `min_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the feature dictionary (with stop words): 23525\n",
      "Size of the feature dictionary (without stop words): 23231\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "# Initialize the CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training data\n",
    "X_train = count_vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "# Get the feature dictionary (vocabulary) size\n",
    "feature_dictionary_size = len(count_vectorizer.vocabulary_)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a new CountVectorizer with English stop words removed\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the new vectorizer on the training data\n",
    "X_train_no_stopwords = count_vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "# Get the feature dictionary (vocabulary) size without stop words\n",
    "feature_dictionary_size_no_stopwords = len(count_vectorizer.vocabulary_)\n",
    "\n",
    "\n",
    "print(f\"Size of the feature dictionary (with stop words): {feature_dictionary_size}\")\n",
    "print(f\"Size of the feature dictionary (without stop words): {feature_dictionary_size_no_stopwords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count_vectorizer.fit_transform(data_train.data)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, data_train.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_regression_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8297872340425532\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.88      0.81      0.85       124\n",
      "       comp.windows.x       0.91      0.90      0.91       107\n",
      "         misc.forsale       0.85      0.75      0.80       131\n",
      "            rec.autos       0.70      0.88      0.78       108\n",
      "\n",
      "             accuracy                           0.83       470\n",
      "            macro avg       0.84      0.83      0.83       470\n",
      "         weighted avg       0.84      0.83      0.83       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "report = classification_report(y_valid, y_pred, target_names=data_train.target_names)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set (without refitting the vectorizer): 0.8339719029374202\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.85      0.79      0.82       385\n",
      "       comp.windows.x       0.94      0.82      0.88       395\n",
      "         misc.forsale       0.86      0.79      0.83       390\n",
      "            rec.autos       0.73      0.93      0.82       396\n",
      "\n",
      "             accuracy                           0.83      1566\n",
      "            macro avg       0.85      0.83      0.83      1566\n",
      "         weighted avg       0.85      0.83      0.84      1566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test set using the trained vectorizer with no stop words\n",
    "X_test_transformed = count_vectorizer.transform(data_test.data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = logistic_regression_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "accuracy_test = accuracy_score(data_test.target, y_test_pred)\n",
    "report_test = classification_report(data_test.target, y_test_pred, target_names=data_test.target_names)\n",
    "\n",
    "print(f\"Accuracy on the test set (without refitting the vectorizer): {accuracy_test}\")\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8212765957446808\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.89      0.79      0.84       124\n",
      "       comp.windows.x       0.89      0.90      0.89       107\n",
      "         misc.forsale       0.85      0.76      0.80       131\n",
      "            rec.autos       0.69      0.86      0.77       108\n",
      "\n",
      "             accuracy                           0.82       470\n",
      "            macro avg       0.83      0.83      0.82       470\n",
      "         weighted avg       0.83      0.82      0.82       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize CountVectorizer with restricted features and custom max_df and min_df\n",
    "count_vectorizer = \n",
    ", stop_words='english')\n",
    "\n",
    "# Fit the vectorizer on the training data\n",
    "X_train = count_vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "# Get the size of the feature dictionary\n",
    "feature_dictionary_size = len(count_vectorizer.vocabulary_)\n",
    "\n",
    "# Split the data into a training and validation set\n",
    "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train, data_train.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model on the training data\n",
    "logistic_regression_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = logistic_regression_model.predict(X_valid)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "report = classification_report(y_valid, y_pred, target_names=data_train.target_names)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test Out Hashing and TF-IDF.\n",
    "\n",
    "Let's see if hashing or TF-IDF improves our accuracy.\n",
    "\n",
    "1) Initialize a HashingVectorizer and repeat the test with no restriction on the number of features.\n",
    "- Does the score improve with respect to the CountVectorizer?\n",
    "- Print out the number of features for this model.\n",
    "- Initialize a TF-IDF vectorizer and repeat the analysis above.\n",
    "- Print out the number of features for this model.\n",
    "\n",
    "**Bonus**\n",
    "- Change the parameters of either (or both) models to improve your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (HashingVectorizer): 1048576\n",
      "Accuracy (HashingVectorizer): 0.851063829787234\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.88      0.84      0.86       124\n",
      "       comp.windows.x       0.88      0.93      0.91       107\n",
      "         misc.forsale       0.89      0.77      0.83       131\n",
      "            rec.autos       0.75      0.88      0.81       108\n",
      "\n",
      "             accuracy                           0.85       470\n",
      "            macro avg       0.85      0.86      0.85       470\n",
      "         weighted avg       0.86      0.85      0.85       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "# Initialize HashingVectorizer with no restriction on the number of features\n",
    "hashing_vectorizer = HashingVectorizer(stop_words='english')\n",
    "\n",
    "# Transform the training data using HashingVectorizer\n",
    "X_train_hashing = hashing_vectorizer.transform(data_train.data)\n",
    "\n",
    "# Split the data into a training and validation set\n",
    "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train_hashing, data_train.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model on the training data\n",
    "logistic_regression_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = logistic_regression_model.predict(X_valid)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy_hashing = accuracy_score(y_valid, y_pred)\n",
    "report_hashing = classification_report(y_valid, y_pred, target_names=data_train.target_names)\n",
    "\n",
    "# Print the number of features for HashingVectorizer\n",
    "num_features_hashing = X_train_hashing.shape[1]\n",
    "print(f\"Number of features (HashingVectorizer): {num_features_hashing}\")\n",
    "print(f\"Accuracy (HashingVectorizer): {accuracy_hashing}\")\n",
    "print(report_hashing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set (without refitting the vectorizer): 0.8448275862068966\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.85      0.77      0.81       385\n",
      "       comp.windows.x       0.93      0.87      0.90       395\n",
      "         misc.forsale       0.90      0.80      0.85       390\n",
      "            rec.autos       0.74      0.93      0.82       396\n",
      "\n",
      "             accuracy                           0.84      1566\n",
      "            macro avg       0.85      0.84      0.85      1566\n",
      "         weighted avg       0.85      0.84      0.85      1566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test set using the trained vectorizer with no stop words\n",
    "X_test_transformed = hashing_vectorizer.transform(data_test.data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = logistic_regression_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "accuracy_test = accuracy_score(data_test.target, y_test_pred)\n",
    "report_test = classification_report(data_test.target, y_test_pred, target_names=data_test.target_names)\n",
    "\n",
    "print(f\"Accuracy on the test set (without refitting the vectorizer): {accuracy_test}\")\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (TF-IDF Vectorizer): 23231\n",
      "Accuracy (TF-IDF Vectorizer): 0.8638297872340426\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.93      0.86      0.90       124\n",
      "       comp.windows.x       0.94      0.94      0.94       107\n",
      "         misc.forsale       0.88      0.76      0.81       131\n",
      "            rec.autos       0.73      0.92      0.81       108\n",
      "\n",
      "             accuracy                           0.86       470\n",
      "            macro avg       0.87      0.87      0.87       470\n",
      "         weighted avg       0.87      0.86      0.86       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer with no restriction on the number of features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=None, stop_words='english')\n",
    "\n",
    "# Transform the training data using TF-IDF Vectorizer\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "# Split the data into a training and validation set\n",
    "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train_tfidf, data_train.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model on the training data\n",
    "logistic_regression_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = logistic_regression_model.predict(X_valid)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy_tfidf = accuracy_score(y_valid, y_pred)\n",
    "report_tfidf = classification_report(y_valid, y_pred, target_names=data_train.target_names)\n",
    "\n",
    "# Print the number of features for TF-IDF Vectorizer\n",
    "num_features_tfidf = X_train_tfidf.shape[1]\n",
    "print(f\"Number of features (TF-IDF Vectorizer): {num_features_tfidf}\")\n",
    "print(f\"Accuracy (TF-IDF Vectorizer): {accuracy_tfidf}\")\n",
    "print(report_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set (without refitting the vectorizer): 0.8671775223499362\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.90      0.80      0.85       385\n",
      "       comp.windows.x       0.94      0.90      0.92       395\n",
      "         misc.forsale       0.89      0.81      0.85       390\n",
      "            rec.autos       0.77      0.96      0.85       396\n",
      "\n",
      "             accuracy                           0.87      1566\n",
      "            macro avg       0.88      0.87      0.87      1566\n",
      "         weighted avg       0.88      0.87      0.87      1566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test set using the trained vectorizer with no stop words\n",
    "X_test_transformed = tfidf_vectorizer.transform(data_test.data)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = logistic_regression_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "accuracy_test = accuracy_score(data_test.target, y_test_pred)\n",
    "report_test = classification_report(data_test.target, y_test_pred, target_names=data_test.target_names)\n",
    "\n",
    "print(f\"Accuracy on the test set (without refitting the vectorizer): {accuracy_test}\")\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (HashingVectorizer): 1048576\n",
      "Accuracy (HashingVectorizer): 0.8468085106382979\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.91      0.82      0.86       124\n",
      "       comp.windows.x       0.87      0.93      0.90       107\n",
      "         misc.forsale       0.90      0.76      0.82       131\n",
      "            rec.autos       0.73      0.91      0.81       108\n",
      "\n",
      "             accuracy                           0.85       470\n",
      "            macro avg       0.85      0.85      0.85       470\n",
      "         weighted avg       0.86      0.85      0.85       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "# Initialize HashingVectorizer with no restriction on the number of features\n",
    "hashing_vectorizer = HashingVectorizer(n_features=2**20, ngram_range=(1, 3),stop_words='english')\n",
    "\n",
    "# Transform the training data using HashingVectorizer\n",
    "X_train_hashing = hashing_vectorizer.transform(data_train.data)\n",
    "\n",
    "# Split the data into a training and validation set\n",
    "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train_hashing, data_train.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model on the training data\n",
    "logistic_regression_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = logistic_regression_model.predict(X_valid)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy_hashing = accuracy_score(y_valid, y_pred)\n",
    "report_hashing = classification_report(y_valid, y_pred, target_names=data_train.target_names)\n",
    "\n",
    "# Print the number of features for HashingVectorizer\n",
    "num_features_hashing = X_train_hashing.shape[1]\n",
    "print(f\"Number of features (HashingVectorizer): {num_features_hashing}\")\n",
    "print(f\"Accuracy (HashingVectorizer): {accuracy_hashing}\")\n",
    "print(report_hashing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set (without refitting the vectorizer): 0.8448275862068966\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.88      0.76      0.82       385\n",
      "       comp.windows.x       0.92      0.88      0.90       395\n",
      "         misc.forsale       0.91      0.79      0.84       390\n",
      "            rec.autos       0.73      0.94      0.82       396\n",
      "\n",
      "             accuracy                           0.84      1566\n",
      "            macro avg       0.86      0.84      0.85      1566\n",
      "         weighted avg       0.86      0.84      0.85      1566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test set using the trained vectorizer with no stop words\n",
    "X_test_transformed = hashing_vectorizer.transform(data_test.data)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = logistic_regression_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "accuracy_test = accuracy_score(data_test.target, y_test_pred)\n",
    "report_test = classification_report(data_test.target, y_test_pred, target_names=data_test.target_names)\n",
    "\n",
    "print(f\"Accuracy on the test set (without refitting the vectorizer): {accuracy_test}\")\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (TF-IDF Vectorizer): 1000\n",
      "Accuracy (TF-IDF Vectorizer): 0.8404255319148937\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.90      0.83      0.87       124\n",
      "       comp.windows.x       0.90      0.91      0.90       107\n",
      "         misc.forsale       0.88      0.76      0.81       131\n",
      "            rec.autos       0.71      0.89      0.79       108\n",
      "\n",
      "             accuracy                           0.84       470\n",
      "            macro avg       0.85      0.85      0.84       470\n",
      "         weighted avg       0.85      0.84      0.84       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer with no restriction on the number of features\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,  # You can adjust this parameter\n",
    "    ngram_range=(1, 2),  # Consider unigrams and bigrams\n",
    "    stop_words='english',  # Remove common English stop words\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Transform the training data using TF-IDF Vectorizer\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "# Split the data into a training and validation set\n",
    "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train_tfidf, data_train.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model on the training data\n",
    "logistic_regression_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = logistic_regression_model.predict(X_valid)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy_tfidf = accuracy_score(y_valid, y_pred)\n",
    "report_tfidf = classification_report(y_valid, y_pred, target_names=data_train.target_names)\n",
    "\n",
    "# Print the number of features for TF-IDF Vectorizer\n",
    "num_features_tfidf = X_train_tfidf.shape[1]\n",
    "print(f\"Number of features (TF-IDF Vectorizer): {num_features_tfidf}\")\n",
    "print(f\"Accuracy (TF-IDF Vectorizer): {accuracy_tfidf}\")\n",
    "print(report_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set (without refitting the vectorizer): 0.8326947637292464\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.84      0.77      0.81       385\n",
      "       comp.windows.x       0.91      0.84      0.88       395\n",
      "         misc.forsale       0.87      0.81      0.83       390\n",
      "            rec.autos       0.74      0.91      0.82       396\n",
      "\n",
      "             accuracy                           0.83      1566\n",
      "            macro avg       0.84      0.83      0.83      1566\n",
      "         weighted avg       0.84      0.83      0.83      1566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test set using the trained vectorizer with no stop words\n",
    "X_test_transformed = tfidf_vectorizer.transform(data_test.data)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = logistic_regression_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "accuracy_test = accuracy_score(data_test.target, y_test_pred)\n",
    "report_test = classification_report(data_test.target, y_test_pred, target_names=data_test.target_names)\n",
    "\n",
    "print(f\"Accuracy on the test set (without refitting the vectorizer): {accuracy_test}\")\n",
    "print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. [Bonus] Robust Text Preprocessing\n",
    "\n",
    "Your mission, should you choose to accept it, is to write a preprocessing function for all of your text.  This functions should\n",
    "\n",
    "- convert all text to lowercase,\n",
    "- remove punctuation,\n",
    "- stem or lemmatize each word of the text,\n",
    "- remove stopwords.\n",
    "\n",
    "The function should receive one string of text and return the processed text.\n",
    "\n",
    "Once you have built your function, use it to process your train and test data, then fit a Logistic Regression model to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "    # Tokenize the text (split it into words)\n",
    "    words = text.split()\n",
    "\n",
    "    # Apply stemming to each word\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    # Join the processed words back into a single string\n",
    "    processed_text = ' '.join(words)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and update the text data in data_train\n",
    "for i in range(len(data_train.data)):\n",
    "    data_train.data[i] = preprocess_text(data_train.data[i])\n",
    "\n",
    "# Preprocess and update the text data in test\n",
    "for i in range(len(data_test.data)):\n",
    "    data_test.data[i] = preprocess_text(data_test.data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (TF-IDF Vectorizer): 21845\n",
      "Accuracy (TF-IDF Vectorizer): 0.8595744680851064\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.91      0.85      0.88       124\n",
      "       comp.windows.x       0.92      0.93      0.92       107\n",
      "         misc.forsale       0.88      0.76      0.82       131\n",
      "            rec.autos       0.75      0.93      0.83       108\n",
      "\n",
      "             accuracy                           0.86       470\n",
      "            macro avg       0.87      0.87      0.86       470\n",
      "         weighted avg       0.87      0.86      0.86       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer with no restriction on the number of features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=None, stop_words='english')\n",
    "\n",
    "# Transform the training data using TF-IDF Vectorizer\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "# Split the data into a training and validation set\n",
    "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train_tfidf, data_train.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Fit the logistic regression model on the training data\n",
    "logistic_regression_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = logistic_regression_model.predict(X_valid)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "accuracy_tfidf = accuracy_score(y_valid, y_pred)\n",
    "report_tfidf = classification_report(y_valid, y_pred, target_names=data_train.target_names)\n",
    "\n",
    "# Print the number of features for TF-IDF Vectorizer\n",
    "num_features_tfidf = X_train_tfidf.shape[1]\n",
    "print(f\"Number of features (TF-IDF Vectorizer): {num_features_tfidf}\")\n",
    "print(f\"Accuracy (TF-IDF Vectorizer): {accuracy_tfidf}\")\n",
    "print(report_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set (without refitting the vectorizer): 0.8607918263090677\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "comp.sys.mac.hardware       0.87      0.80      0.84       385\n",
      "       comp.windows.x       0.95      0.88      0.91       395\n",
      "         misc.forsale       0.88      0.82      0.85       390\n",
      "            rec.autos       0.77      0.94      0.85       396\n",
      "\n",
      "             accuracy                           0.86      1566\n",
      "            macro avg       0.87      0.86      0.86      1566\n",
      "         weighted avg       0.87      0.86      0.86      1566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test set using the trained vectorizer with no stop words\n",
    "X_test_transformed = tfidf_vectorizer.transform(data_test.data)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = logistic_regression_model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "accuracy_test = accuracy_score(data_test.target, y_test_pred)\n",
    "report_test = classification_report(data_test.target, y_test_pred, target_names=data_test.target_names)\n",
    "\n",
    "print(f\"Accuracy on the test set (without refitting the vectorizer): {accuracy_test}\")\n",
    "print(report_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
